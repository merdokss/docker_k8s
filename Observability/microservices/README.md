# Mikroserwisy z OpenTelemetry - Distributed Tracing Demo

Zestaw mikroserwisÃ³w demonstrujÄ…cych distributed tracing z OpenTelemetry i Grafana Tempo.

## ğŸ—ï¸ Architektura

```
Frontend Service (Python/Flask)
    â†“
Service A (Node.js/Express)
    â†“
Service B (Python/Flask)
    â†“
Service C (Node.js/Express) - koÅ„cowy serwis
```

KaÅ¼dy serwis:
- WywoÅ‚uje nastÄ™pny serwis w Å‚aÅ„cuchu
- WysyÅ‚a traces do Grafana Tempo przez OpenTelemetry
- Propaguje trace context miÄ™dzy serwisami
- Generuje strukturalne logi JSON

## ğŸ“‹ Serwisy

### Frontend Service (Python)
- **Port**: 8080
- **Endpoints**:
  - `GET /` - Informacje o serwisie
  - `GET /api/order?order_id=xxx` - Tworzy zamÃ³wienie (wywoÅ‚uje service-a)
  - `GET /api/user?user_id=xxx` - Pobiera uÅ¼ytkownika (wywoÅ‚uje service-a)
  - `GET /health` - Health check

### Service A (Node.js)
- **Port**: 8080
- **Endpoints**:
  - `GET /` - Informacje o serwisie
  - `GET /api/process?order_id=xxx` - Przetwarza zamÃ³wienie (wywoÅ‚uje service-b)
  - `GET /api/user?user_id=xxx` - Pobiera uÅ¼ytkownika (wywoÅ‚uje service-b)
  - `GET /health` - Health check

### Service B (Python)
- **Port**: 8080
- **Endpoints**:
  - `GET /` - Informacje o serwisie
  - `GET /api/validate?order_id=xxx` - Waliduje zamÃ³wienie (wywoÅ‚uje service-c)
  - `GET /api/user?user_id=xxx` - Pobiera uÅ¼ytkownika
  - `GET /health` - Health check

### Service C (Node.js)
- **Port**: 8080
- **Endpoints**:
  - `GET /` - Informacje o serwisie
  - `GET /api/complete?order_id=xxx` - KoÅ„czy przetwarzanie zamÃ³wienia
  - `GET /api/user?user_id=xxx` - Pobiera szczegÃ³Å‚y uÅ¼ytkownika
  - `GET /api/orders/:orderId` - Pobiera zamÃ³wienie
  - `GET /health` - Health check

## ğŸš€ Instalacja

### 1. Zbuduj obrazy Docker

```bash
cd microservices
chmod +x build.sh
./build.sh
```

Lub zbuduj kaÅ¼dy serwis osobno:

```bash
# Frontend Service
cd frontend-service
docker build -t dawidsages.azurecr.io/frontend-service:latest .
cd ..

# Service A
cd service-a
docker build -t dawidsages.azurecr.io/service-a:latest .
cd ..

# Service B
cd service-b
docker build -t dawidsages.azurecr.io/service-b:latest .
cd ..

# Service C
cd service-c
docker build -t dawidsages.azurecr.io/service-c:latest .
cd ..
```

### 2. Wypchnij obrazy do registry (opcjonalnie)

```bash
docker login dawidsages.azurecr.io
docker push dawidsages.azurecr.io/frontend-service:latest
docker push dawidsages.azurecr.io/service-a:latest
docker push dawidsages.azurecr.io/service-b:latest
docker push dawidsages.azurecr.io/service-c:latest
```

### 3. Zainstaluj w Kubernetes

```bash
kubectl apply -f deployment.yaml
```

### 4. SprawdÅº status

```bash
kubectl get pods -l 'app in (frontend-service,service-a,service-b,service-c)'
kubectl get svc -l 'app in (frontend-service,service-a,service-b,service-c)'
```

## ğŸ§ª Testowanie

### Generuj load na serwisy

```bash
chmod +x generate-load.sh
./generate-load.sh
```

Lub rÄ™cznie:

```bash
# Port-forward do frontend-service
kubectl port-forward svc/frontend-service 8080:8080

# W osobnym terminalu - wywoÅ‚aj endpointy
curl http://localhost:8080/api/order?order_id=test-123
curl http://localhost:8080/api/user?user_id=user-123
```

### WywoÅ‚aj przez kubectl

```bash
# Uruchom pod z curl
kubectl run -it --rm curl-test --image=curlimages/curl --restart=Never -- \
  sh -c "while true; do curl -s http://frontend-service.default.svc.cluster.local:8080/api/order?order_id=test-\$(date +%s); sleep 2; done"
```

## ğŸ“Š Observability

### Traces w Grafana Tempo

1. OtwÃ³rz Grafana (http://localhost:3000 lub LoadBalancer IP)
2. PrzejdÅº do **Explore**
3. Wybierz datasource: **Tempo**
4. Wyszukaj po service name:
   - `frontend-service`
   - `service-a`
   - `service-b`
   - `service-c`
5. Kliknij na trace, aby zobaczyÄ‡ peÅ‚ny Å‚aÅ„cuch wywoÅ‚aÅ„

### Service Map

W Grafana Explore z Tempo, moÅ¼esz zobaczyÄ‡:
- **Service Map** - wizualizacjÄ™ zaleÅ¼noÅ›ci miÄ™dzy serwisami
- **Trace Timeline** - czas wykonania kaÅ¼dego span w Å‚aÅ„cuchu
- **Span Details** - szczegÃ³Å‚y kaÅ¼dego wywoÅ‚ania

### PrzykÅ‚adowy Trace

Gdy wywoÅ‚asz `/api/order` na frontend-service, zobaczysz trace z:
1. `frontend-service` - span gÅ‚Ã³wny
2. `frontend-service.call_service_a` - wywoÅ‚anie service-a
3. `service-a` - przetwarzanie w service-a
4. `service-a` (HTTP call) - wywoÅ‚anie service-b
5. `service-b` - walidacja w service-b
6. `service-b.call_service_c` - wywoÅ‚anie service-c
7. `service-c` - koÅ„cowe przetwarzanie

## ğŸ” Logi

Wszystkie serwisy generujÄ… strukturalne logi JSON. MoÅ¼esz je przeglÄ…daÄ‡ w Loki:

```bash
# Logi z frontend-service
kubectl logs -l app=frontend-service --tail=50 -f

# Logi ze wszystkich serwisÃ³w
kubectl logs -l 'app in (frontend-service,service-a,service-b,service-c)' --tail=50
```

W Grafana Explore z Loki:
```
{app="frontend-service"} | json
{app="service-a"} | json
```

## ğŸ§¹ UsuniÄ™cie

```bash
kubectl delete -f deployment.yaml
```

## ğŸ“ Uwagi

- Wszystkie serwisy sÄ… skonfigurowane do wysyÅ‚ania traces do `tempo.monitoring.svc.cluster.local:4317`
- Trace context jest automatycznie propagowany przez OpenTelemetry instrumentation
- KaÅ¼dy serwis ma health check endpoint
- Serwisy sÄ… skalowalne (replicas: 2)
- Resource limits sÄ… ustawione dla kaÅ¼dego serwisu

## ğŸ¯ Ä†wiczenia

1. **Obserwuj distributed traces**: WywoÅ‚aj `/api/order` i zobacz peÅ‚ny trace w Tempo
2. **Analizuj czas wykonania**: SprawdÅº ktÃ³ry serwis jest najwolniejszy
3. **Service Map**: Zobacz wizualizacjÄ™ zaleÅ¼noÅ›ci miÄ™dzy serwisami
4. **Trace propagation**: SprawdÅº jak trace ID jest propagowany miÄ™dzy serwisami
5. **BÅ‚Ä™dy**: Dodaj endpoint generujÄ…cy bÅ‚Ä™dy i zobacz jak sÄ… Å›ledzone w traces

