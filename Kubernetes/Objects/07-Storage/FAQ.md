## â“ FAQ - CzÄ™sto zadawane pytania

### Q1: JeÅ›li PV ma 100GB, a PVC Å¼Ä…da 50GB, co siÄ™ dzieje z pozostaÅ‚ymi 50GB?

**OdpowiedÅº:** PozostaÅ‚e 50GB "przepada" - nie moÅ¼e byÄ‡ uÅ¼yte przez inny PVC.

#### SzczegÃ³Å‚y:

**Co siÄ™ dzieje przy binding:**
```bash
# PV utworzony na 100GB
kubectl get pv
# NAME    CAPACITY   STATUS      
# my-pv   100Gi      Available

# PVC Å¼Ä…da tylko 50GB
kubectl get pvc
# NAME     STATUS   VOLUME   CAPACITY
# my-pvc   Bound    my-pv    100Gi    â† Dostaje caÅ‚y PV!
```

**Kluczowe punkty:**
- âœ… PVC binduje siÄ™ z **caÅ‚ym PV** (nie z czÄ™Å›ciÄ…)
- âœ… Aplikacja w Podzie **moÅ¼e uÅ¼ywaÄ‡ wszystkich 100GB**
- âŒ Å»aden inny PVC **nie moÅ¼e** uÅ¼yÄ‡ pozostaÅ‚ych 50GB
- ğŸ’° W cloud **pÅ‚acisz za caÅ‚e 100GB**

#### PrzykÅ‚ad - co widzi aplikacja:

```yaml
# PVC Å¼Ä…da 50GB, PV ma 100GB
apiVersion: v1
kind: PersistentVolumeClaim
metadata:
  name: my-pvc
spec:
  resources:
    requests:
      storage: 50Gi
  storageClassName: manual
```

```bash
# W Podzie sprawdzamy dostÄ™pne miejsce
kubectl exec -it my-pod -- df -h /data
# Filesystem      Size  Used Avail Use% Mounted on
# /dev/sda1       100G  1.0G   99G   1% /data  â† PeÅ‚ne 100GB dostÄ™pne!
```

#### Implikacje kosztowe w cloud:

```
AWS/GCP/Azure:
- Utworzono fizyczny disk: 100GB
- PVC "wie" o: 50GB  
- Kubernetes quota: 50GB
- Faktury: ğŸ’° 100GB!
- Marnotrawstwo: 50GB
```

#### âœ… Jak tego uniknÄ…Ä‡?

**RozwiÄ…zanie 1: Dynamic Provisioning (NAJLEPSZE!)**

```yaml
apiVersion: v1
kind: PersistentVolumeClaim
metadata:
  name: my-pvc
spec:
  storageClassName: fast-ssd  # âœ… Automatycznie utworzy PV dokÅ‚adnego rozmiaru!
  resources:
    requests:
      storage: 50Gi  # Dostaniesz DOKÅADNIE 50GB
```

**Rezultat:**
```bash
kubectl get pv,pvc
# PV: 50Gi  âœ… DokÅ‚adny rozmiar!
# PVC: 50Gi âœ… Zero marnotrawstwa!
```

**RozwiÄ…zanie 2: Dopasuj rozmiary PV i PVC**

```yaml
# âœ… DOBRZE - ten sam rozmiar
apiVersion: v1
kind: PersistentVolume
metadata:
  name: pv-50gb
spec:
  capacity:
    storage: 50Gi  # DokÅ‚adnie tyle ile potrzeba
---
apiVersion: v1
kind: PersistentVolumeClaim
metadata:
  name: pvc-50gb
spec:
  resources:
    requests:
      storage: 50Gi  # Ten sam rozmiar
```

**RozwiÄ…zanie 3: Volume Expansion**

```yaml
apiVersion: storage.k8s.io/v1
kind: StorageClass
metadata:
  name: expandable
provisioner: kubernetes.io/gce-pd
allowVolumeExpansion: true  # âœ… MoÅ¼na zwiÄ™kszaÄ‡!
```

```bash
# Zacznij od mniejszego
# PÃ³Åºniej zwiÄ™ksz gdy potrzeba
kubectl patch pvc my-pvc -p '{"spec":{"resources":{"requests":{"storage":"100Gi"}}}}'
```

#### ğŸ“Š PorÃ³wnanie: Static vs Dynamic

| Aspekt | Static (rÄ™czny PV) | Dynamic (StorageClass) |
|--------|-------------------|------------------------|
| **Marnotrawstwo** | âš ï¸ Wysokie ryzyko | âœ… Zero marnotrawstwa |
| **ElastycznoÅ›Ä‡** | âŒ Musisz przewidzieÄ‡ rozmiar | âœ… DokÅ‚adny rozmiar |
| **Koszty** | ğŸ’° PÅ‚acisz za nadmiar | ğŸ’° PÅ‚acisz za dokÅ‚adne uÅ¼ycie |
| **ZarzÄ…dzanie** | ğŸ˜“ RÄ™czna praca | ğŸ˜Š Automatyczne |

#### ğŸ¯ ZÅ‚ota zasada:

> **PV i PVC powinny byÄ‡ tego samego rozmiaru!**
> 
> JeÅ›li uÅ¼ywasz static provisioning i PV jest wiÄ™kszy niÅ¼ PVC - marnujesz storage (i pieniÄ…dze w cloud).

---

### Q2: Co to jest provisioner `kubernetes.io/no-provisioner`?

**OdpowiedÅº:** To specjalny "pseudo-provisioner" sygnalizujÄ…cy, Å¼e StorageClass **NIE obsÅ‚uguje** dynamic provisioning i PV muszÄ… byÄ‡ tworzone rÄ™cznie.

#### Co to oznacza?

```yaml
apiVersion: storage.k8s.io/v1
kind: StorageClass
metadata:
  name: local-storage
provisioner: kubernetes.io/no-provisioner  # â† "Nie twÃ³rz automatycznie PV!"
volumeBindingMode: WaitForFirstConsumer
```

**Komunikat do Kubernetes:**
> "Ta StorageClass nie ma automatycznego provisionera. Administrator musi rÄ™cznie utworzyÄ‡ PV."

#### ğŸ”„ RÃ³Å¼nica w przepÅ‚ywie:

**Dynamic Provisioning (normalny provisioner):**
```
PVC â†’ StorageClass â†’ (AUTO-TWORZY PV) â†’ Binding â†’ Pod
```

**No-Provisioner:**
```
Admin rÄ™cznie tworzy PV
       â†“
PVC â†’ StorageClass â†’ (SZUKA ISTNIEJÄ„CEGO PV) â†’ Binding â†’ Pod
```

#### ğŸ¯ Kiedy uÅ¼ywaÄ‡?

**âœ… GÅÃ“WNY USE CASE: Local Storage**

Local volumes to dyski przywiÄ…zane do konkretnego Node (np. SSD zainstalowany lokalnie).

```yaml
apiVersion: storage.k8s.io/v1
kind: StorageClass
metadata:
  name: fast-local
provisioner: kubernetes.io/no-provisioner
volumeBindingMode: WaitForFirstConsumer  # âœ… KRYTYCZNE dla local storage!
```

**Dlaczego `no-provisioner`?**
- Nie moÅ¼na automatycznie "stworzyÄ‡" dysku na Node
- Admin musi fizycznie przygotowaÄ‡ dyski
- Kubernetes tylko zarzÄ…dza bindings

#### ğŸ“‹ Kompletny przykÅ‚ad: Local Storage

**Krok 1: Przygotowanie Node**

```bash
# Na Node
ssh node1
sudo mkdir -p /mnt/disks/ssd1

# Opcjonalnie: zamontuj fizyczny dysk
sudo mkfs.ext4 /dev/sdb
sudo mount /dev/sdb /mnt/disks/ssd1
```

**Krok 2: StorageClass**

```yaml
apiVersion: storage.k8s.io/v1
kind: StorageClass
metadata:
  name: fast-local
provisioner: kubernetes.io/no-provisioner
volumeBindingMode: WaitForFirstConsumer
reclaimPolicy: Retain
```

**Krok 3: PV (rÄ™cznie przez admina)**

```yaml
apiVersion: v1
kind: PersistentVolume
metadata:
  name: local-pv-node1
spec:
  capacity:
    storage: 100Gi
  accessModes:
    - ReadWriteOnce
  persistentVolumeReclaimPolicy: Retain
  storageClassName: fast-local
  local:
    path: /mnt/disks/ssd1
  nodeAffinity:  # âœ… WYMAGANE dla local volumes!
    required:
      nodeSelectorTerms:
      - matchExpressions:
        - key: kubernetes.io/hostname
          operator: In
          values:
          - node1  # PV przywiÄ…zany do tego Node
```

**Krok 4: PVC (user)**

```yaml
apiVersion: v1
kind: PersistentVolumeClaim
metadata:
  name: my-local-pvc
spec:
  accessModes:
    - ReadWriteOnce
  storageClassName: fast-local
  resources:
    requests:
      storage: 50Gi
```

```bash
kubectl apply -f pvc.yaml

# PVC pozostaje w Pending!
kubectl get pvc
# NAME            STATUS    VOLUME   STORAGECLASS
# my-local-pvc    Pending            fast-local
```

**Dlaczego Pending?** 
- `volumeBindingMode: WaitForFirstConsumer`
- Czeka na utworzenie Poda

**Krok 5: Pod**

```yaml
apiVersion: v1
kind: Pod
metadata:
  name: my-app
spec:
  containers:
  - name: app
    image: nginx
    volumeMounts:
    - name: storage
      mountPath: /data
  volumes:
  - name: storage
    persistentVolumeClaim:
      claimName: my-local-pvc
```

```bash
kubectl apply -f pod.yaml

# Teraz nastÄ™puje binding!
kubectl get pvc
# NAME            STATUS   VOLUME           STORAGECLASS
# my-local-pvc    Bound    local-pv-node1   fast-local

kubectl get pod -o wide
# NAME     READY   STATUS    NODE
# my-app   1/1     Running   node1  â† Schedulowany na node1!
```

#### âš¡ volumeBindingMode - KRYTYCZNE!

**WaitForFirstConsumer (âœ… ZALECANE dla local storage)**

```yaml
volumeBindingMode: WaitForFirstConsumer
```

**PrzepÅ‚yw:**
```
1. PVC created â†’ Pending (czeka)
2. Pod created â†’ Scheduler wybiera Node (np. node2)
3. Kubernetes wybiera PV na node2
4. Binding PVC â†” PV
5. Pod startuje
```

**Immediate (âŒ PROBLEMATYCZNE dla local storage)**

```yaml
volumeBindingMode: Immediate
```

**Problem:**
```
1. PVC created â†’ Binduje z random PV (np. na node1)
2. Pod created â†’ MUSI byÄ‡ na node1 (bo volume tam jest)
3. Co jeÅ›li node1 nie ma resources? Pod Pending forever!
```

#### ğŸ“Š PorÃ³wnanie provisionerÃ³w

| Aspekt | no-provisioner | Prawdziwy provisioner |
|--------|----------------|----------------------|
| **Auto-tworzenie PV** | âŒ Nie | âœ… Tak |
| **Admin musi tworzyÄ‡ PV** | âœ… Tak | âŒ Nie |
| **Use case** | Local storage, manual | Cloud storage, auto-scaling |
| **ElastycznoÅ›Ä‡** | âš ï¸ Ograniczona | âœ… PeÅ‚na |
| **Kontrola** | âœ… PeÅ‚na | âš ï¸ Mniej kontroli |
| **Overhead** | ğŸ˜“ DuÅ¼y (rÄ™czna praca) | ğŸ˜Š Minimalny |

#### ğŸ¯ Kiedy uÅ¼ywaÄ‡ `no-provisioner`?

**âœ… UÅ»YWAJ gdy:**
- Local storage (SSD/NVMe na Nodes)
- Wysokowydajne bazy danych wymagajÄ…ce local disks
- Specjalne wymagania security/compliance
- Legacy storage bez CSI driver

**âŒ NIE UÅ»YWAJ gdy:**
- Masz dostÄ™p do cloud storage (AWS EBS, GCE PD, Azure Disk)
- Potrzebujesz szybkiego skalowania
- Masz maÅ‚y team ops (rÄ™czne zarzÄ…dzanie jest czasochÅ‚onne)

#### ğŸ’¡ Best Practices dla local storage

**âœ… DO:**

1. **Zawsze uÅ¼ywaj WaitForFirstConsumer**
```yaml
volumeBindingMode: WaitForFirstConsumer
```

2. **Dodawaj nodeAffinity**
```yaml
spec:
  nodeAffinity:
    required:
      nodeSelectorTerms:
      - matchExpressions:
        - key: kubernetes.io/hostname
          operator: In
          values:
          - node1
```

3. **Label PV dla zarzÄ…dzania**
```yaml
metadata:
  labels:
    storage-type: local-ssd
    node: node1
    disk: ssd1
```

**âŒ DON'T:**

1. **Nie uÅ¼ywaj Immediate dla local storage**
2. **Nie zapominaj o nodeAffinity**
3. **Nie uÅ¼ywaj local storage dla stateless apps**

#### ğŸ› ï¸ NarzÄ™dzie pomocnicze

**Local Volume Static Provisioner** - automatyzuje tworzenie local PV:

```yaml
apiVersion: apps/v1
kind: DaemonSet
metadata:
  name: local-volume-provisioner
  namespace: kube-system
spec:
  selector:
    matchLabels:
      app: local-volume-provisioner
  template:
    metadata:
      labels:
        app: local-volume-provisioner
    spec:
      serviceAccountName: local-storage-admin
      containers:
      - name: provisioner
        image: quay.io/external_storage/local-volume-provisioner:v2.5.0
        volumeMounts:
        - name: discovery-vol
          mountPath: /mnt/disks
      volumes:
      - name: discovery-vol
        hostPath:
          path: /mnt/disks
```

**Co robi:**
- Skanuje `/mnt/disks` na kaÅ¼dym Node
- Automatycznie tworzy PV dla znalezionych dyskÃ³w
- Redukuje rÄ™cznÄ… pracÄ™ admina

---

## ğŸ“– Dodatkowe zasoby

### Oficjalna dokumentacja:
- [Kubernetes Storage](https://kubernetes.io/docs/concepts/storage/)
- [Persistent Volumes](https://kubernetes.io/docs/concepts/storage/persistent-volumes/)
- [Storage Classes](https://kubernetes.io/docs/concepts/storage/storage-classes/)
- [Dynamic Volume Provisioning](https://kubernetes.io/docs/concepts/storage/dynamic-provisioning/)
- [Local Persistent Volumes](https://kubernetes.io/docs/concepts/storage/volumes/#local)

### Provisionerzy dla rÃ³Å¼nych platform:
- **AWS EBS CSI Driver**: `ebs.csi.aws.com`
- **Azure Disk CSI Driver**: `disk.csi.azure.com`
- **GCE PD CSI Driver**: `pd.csi.storage.gke.io`
- **NFS**: `nfs.csi.k8s.io`
- **Ceph RBD**: `rbd.csi.ceph.com`
- **Local volumes**: `kubernetes.io/no-provisioner`