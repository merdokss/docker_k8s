# ğŸš€ Kubernetes Maintenance & Upgrade - Kompletne Podsumowanie


### **Zakres**
- âœ… Zero downtime maintenance
- âœ… Upgrade Control Plane i Worker Nodes
- âœ… Scaling zasobÃ³w (vertical & horizontal)
- âœ… Strategie dla rÃ³Å¼nych Å›rodowisk

---

## ğŸ’¡ Filozofia maintenance w K8s

### **"Cattle, not Pets"**

```
âŒ STARE PODEJÅšCIE (Pets):          âœ… NOWE PODEJÅšCIE (Cattle):
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Napraw serwer      â”‚              â”‚ WymieÅ„ node        â”‚
â”‚ Debuguj problem    â”‚              â”‚ Automatyzuj proces â”‚
â”‚ RÄ™czna konfiguracjaâ”‚              â”‚ Infrastructure as Code â”‚
â”‚ DÅ‚ugi downtime     â”‚              â”‚ Zero downtime      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜              â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### **Kluczowe zasady:**
1. **Node'y sÄ… zastÄ™powalne** - nie naprawiamy, tylko wymieniamy
2. **Automatyzacja first** - wszystko w kodzie (Terraform, Ansible)
3. **Rolling updates** - zawsze po jednym node'ie
4. **Test na non-prod** - nigdy nie eksperymentuj na produkcji
5. **Backup etcd** - zawsze przed upgrade

---

## ğŸ”§ Strategie maintenance klastra

### **GÅ‚Ã³wne strategie**

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  1. NODE POOL ROTATION (â­ Najlepsze)              â”‚
â”‚     StwÃ³rz nowy pool â†’ Migruj â†’ UsuÅ„ stary        â”‚
â”‚                                                    â”‚
â”‚  2. ROLLING UPDATE                                 â”‚
â”‚     Node po node: Cordon â†’ Drain â†’ Upgrade        â”‚
â”‚                                                    â”‚
â”‚  3. BLUE-GREEN DEPLOYMENT                          â”‚
â”‚     Dwa peÅ‚ne Å›rodowiska, przeÅ‚Ä…czenie ruchu      â”‚
â”‚                                                    â”‚
â”‚  4. IN-PLACE UPGRADE                               â”‚
â”‚     Upgrade na Å¼ywym node (tylko emergency)       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

### **1ï¸âƒ£ Node Pool Rotation** â­ Rekomendowane

**Proces:**

```
KROK 1: Stary pool              KROK 2: Dodaj nowy pool
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Node 1 (old) â”‚                â”‚ Node 1 (old) â”‚
â”‚ Node 2 (old) â”‚         +      â”‚ Node 2 (old) â”‚
â”‚ Node 3 (old) â”‚                â”‚ Node 4 (new) â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                â”‚ Node 5 (new) â”‚
                                â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â¬‡ï¸                              â¬‡ï¸
KROK 3: Drain stary             KROK 4: UsuÅ„ stary
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Node 1 ğŸ’¨    â”‚                â”‚ Node 4 âœ…    â”‚
â”‚ Node 2 ğŸ’¨    â”‚                â”‚ Node 5 âœ…    â”‚
â”‚ Node 4 â¬†ï¸    â”‚                â”‚ Node 6 âœ…    â”‚
â”‚ Node 5 â¬†ï¸    â”‚                â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Zalety:**
- âœ… Zero downtime
- âœ… Åatwy rollback (zostaw oba pools)
- âœ… Testowanie przed peÅ‚nÄ… migracjÄ…

**Wady:**
- âŒ WyÅ¼szy koszt (2x zasoby przez moment)
- âŒ WiÄ™cej krokÃ³w

---

### **2ï¸âƒ£ Rolling Update**

**Podstawowe komendy:**

```bash
# 1. Zablokuj node (nie przyjmuje nowych podÃ³w)
kubectl cordon <node-name>

# 2. Ewakuuj wszystkie pody z graceful shutdown
kubectl drain <node-name> \
  --ignore-daemonsets \
  --delete-emptydir-data \
  --grace-period=60

# 3. Wykonaj maintenance/upgrade na node
# (upgrade OS, K8s components, dodaj RAM, etc.)

# 4. PrzywrÃ³Ä‡ node do puli
kubectl uncordon <node-name>
```

**Timeline:**

```
Node 1: Cordon â†’ Drain â†’ Upgrade â†’ Uncordon (20 min)
   â¬‡ï¸ czekaj 5-10 min, sprawdÅº stabilnoÅ›Ä‡
Node 2: Cordon â†’ Drain â†’ Upgrade â†’ Uncordon (20 min)
   â¬‡ï¸ czekaj 5-10 min, sprawdÅº stabilnoÅ›Ä‡
Node 3: Cordon â†’ Drain â†’ Upgrade â†’ Uncordon (20 min)
```

**Zalety:**
- âœ… NiÅ¼szy koszt (nie potrzebujesz dodatkowych zasobÃ³w)
- âœ… Prosty proces

**Wady:**
- âš ï¸ DÅ‚uÅ¼szy czas caÅ‚kowitego upgrade
- âš ï¸ Wymaga wystarczajÄ…cej capacity na pozostaÅ‚ych nodes

---

### **3ï¸âƒ£ Blue-Green Deployment**

```
BLUE (produkcja)                GREEN (nowe)
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Pool v1.28    â”‚              â”‚ Pool v1.29    â”‚
â”‚ â”Œâ”€â”€â”€â” â”Œâ”€â”€â”€â”  â”‚              â”‚ â”Œâ”€â”€â”€â” â”Œâ”€â”€â”€â”  â”‚
â”‚ â”‚Podâ”‚ â”‚Podâ”‚  â”‚   PrzeÅ‚Ä…cz   â”‚ â”‚Podâ”‚ â”‚Podâ”‚  â”‚
â”‚ â””â”€â”€â”€â”˜ â””â”€â”€â”€â”˜  â”‚   â”€â”€â”€â”€â”€â”€â”€â”€>  â”‚ â””â”€â”€â”€â”˜ â””â”€â”€â”€â”˜  â”‚
â”‚      â†‘        â”‚              â”‚      â†‘        â”‚
â””â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”˜              â””â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚                              â”‚
    Ruch produkcyjny          Ruch produkcyjny
```

**Zalety:**
- âœ… Natychmiastowy rollback
- âœ… PeÅ‚ne testowanie przed przeÅ‚Ä…czeniem
- âœ… Zero downtime

**Wady:**
- âŒ NajwyÅ¼szy koszt (2x wszystkie zasoby)
- âŒ ZÅ‚oÅ¼onoÅ›Ä‡ zarzÄ…dzania

---

## ğŸ›ï¸ Upgrade Master Nodes (Control Plane)

### **Architektura Control Plane**

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚         CONTROL PLANE                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  ğŸ“¡ kube-apiserver                      â”‚
â”‚     â””â”€> API Gateway                     â”‚
â”‚  ğŸ§  kube-controller-manager             â”‚
â”‚     â””â”€> ZarzÄ…dza kontrolerami          â”‚
â”‚  ğŸ“… kube-scheduler                      â”‚
â”‚     â””â”€> Planuje pody na nodes          â”‚
â”‚  ğŸ’¾ etcd                                â”‚
â”‚     â””â”€> Baza klastra (CRITICAL!)       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

### **On-Premises: Single Master**

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  âš ï¸ UWAGA: BÄ™dzie krÃ³tki downtime!    â”‚
â”‚  API Server: ~30-60s niedostÄ™pny      â”‚
â”‚  Workloady: DziaÅ‚ajÄ… normalnie âœ…     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Proces upgrade:**

```bash
# ============================================
# FAZA 1: Backup etcd (KLUCZOWE!)
# ============================================
ETCDCTL_API=3 etcdctl snapshot save \
  /backup/etcd-$(date +%Y%m%d-%H%M%S).db \
  --endpoints=https://127.0.0.1:2379 \
  --cacert=/etc/kubernetes/pki/etcd/ca.crt \
  --cert=/etc/kubernetes/pki/etcd/server.crt \
  --key=/etc/kubernetes/pki/etcd/server.key

# ============================================
# FAZA 2: Upgrade kubeadm
# ============================================
apt-get update
apt-mark unhold kubeadm
apt-get install -y kubeadm=1.29.0-00
apt-mark hold kubeadm

# SprawdÅº plan
kubeadm upgrade plan

# ============================================
# FAZA 3: Upgrade Control Plane
# âš ï¸ Ten krok restartuje API Server!
# ============================================
kubeadm upgrade apply v1.29.0

# ============================================
# FAZA 4: Upgrade kubelet
# ============================================
apt-mark unhold kubelet kubectl
apt-get install -y kubelet=1.29.0-00 kubectl=1.29.0-00
apt-mark hold kubelet kubectl

systemctl daemon-reload
systemctl restart kubelet

# ============================================
# FAZA 5: Weryfikacja
# ============================================
kubectl get nodes
kubectl version
```

**Timeline:**

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 0-5 min:   Upgrade kubeadm                  â”‚
â”‚ 5-15 min:  Upgrade control plane            â”‚
â”‚            âš ï¸ API unavailable: 30-60s       â”‚
â”‚ 15-20 min: Upgrade kubelet                  â”‚
â”‚ 20-25 min: Weryfikacja                      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
Total: ~25 minut
```

---

### **On-Premises: HA Masters (3 nodes)**

```
                â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                â”‚Load Balancer â”‚
                â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜
                       â”‚
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â–¼              â–¼              â–¼
   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”
   â”‚Master 1â”‚     â”‚Master 2â”‚    â”‚Master 3â”‚
   â””â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”˜

   âœ… Zero downtime podczas upgrade!
```

**Proces (node po node):**

```bash
# ============================================
# MASTER 1 (pierwszy)
# ============================================
ssh master-1

# Upgrade kubeadm
apt-get update && apt-mark unhold kubeadm
apt-get install -y kubeadm=1.29.0-00
apt-mark hold kubeadm

# Upgrade control plane
# UWAGA: "apply" tylko na pierwszym!
kubeadm upgrade apply v1.29.0

# Upgrade kubelet
apt-mark unhold kubelet kubectl
apt-get install -y kubelet=1.29.0-00 kubectl=1.29.0-00
apt-mark hold kubelet kubectl
systemctl daemon-reload
systemctl restart kubelet

# Czekaj 5-10 minut, sprawdÅº stabilnoÅ›Ä‡!

# ============================================
# MASTER 2 i 3 (kolejne mastery)
# ============================================
ssh master-2  # potem master-3

# Upgrade kubeadm
apt-get update && apt-mark unhold kubeadm
apt-get install -y kubeadm=1.29.0-00
apt-mark hold kubeadm

# Upgrade control plane
# UWAGA: "node" zamiast "apply"!
kubeadm upgrade node

# Upgrade kubelet
apt-mark unhold kubelet kubectl
apt-get install -y kubelet=1.29.0-00 kubectl=1.29.0-00
apt-mark hold kubelet kubectl
systemctl daemon-reload
systemctl restart kubelet
```

**Etcd cluster pozostaje dostÄ™pny:**

```
PRZED:          PODCZAS:        PO:
M1: etcd âœ…     M1: etcd âœ…     M1: etcd âœ…
M2: etcd âœ…  â†’  M2: etcd âš ï¸  â†’  M2: etcd âœ…
M3: etcd âœ…     M3: etcd âœ…     M3: etcd âœ…

Quorum: 3/3     Quorum: 2/3     Quorum: 3/3
                (wystarczy!)
```

---

### **Azure AKS: Managed Control Plane**

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚    AZURE MANAGED CONTROL PLANE          â”‚
â”‚    (nie masz dostÄ™pu SSH)               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  ğŸ”’ Microsoft zarzÄ…dza:                 â”‚
â”‚     - API Server (HA + Load Balanced)   â”‚
â”‚     - etcd (auto backups)               â”‚
â”‚     - Scheduler + Controller Manager    â”‚
â”‚                                         â”‚
â”‚  âœ… Zawsze HA (99.95% SLA)              â”‚
â”‚  âœ… Zero downtime upgrade               â”‚
â”‚  âœ… Automatyczne backupy                â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Metoda 1: Basic upgrade**

```bash
# Upgrade control plane + wszystkie node pools
az aks upgrade \
  --resource-group my-rg \
  --name my-cluster \
  --kubernetes-version 1.29.0
```

**Metoda 2: Control plane osobno (rekomendowane)**

```bash
# KROK 1: Upgrade tylko control plane
az aks upgrade \
  --resource-group my-rg \
  --name my-cluster \
  --kubernetes-version 1.29.0 \
  --control-plane-only

# âœ… Zero downtime
# âœ… Workloady nie dotkniÄ™te
# âš ï¸ Version skew: Master v1.29, Nodes v1.28 (OK!)

# KROK 2: Upgrade node pools pÃ³Åºniej (w swoim czasie)
az aks nodepool upgrade \
  --resource-group my-rg \
  --cluster-name my-cluster \
  --name nodepool1 \
  --kubernetes-version 1.29.0
```

**Metoda 3: Blue-Green w AKS**

```bash
# 1. Upgrade control plane
az aks upgrade \
  --resource-group my-rg \
  --name my-cluster \
  --kubernetes-version 1.29.0 \
  --control-plane-only

# 2. Dodaj nowy node pool (green)
az aks nodepool add \
  --resource-group my-rg \
  --cluster-name my-cluster \
  --name greenpool \
  --kubernetes-version 1.29.0 \
  --node-count 3

# 3. Oznacz stary pool jako NoSchedule
kubectl taint nodes -l agentpool=bluepool \
  upgrade=in-progress:NoSchedule

# 4. Drain stary pool (stopniowo)
kubectl drain <node-name> \
  --ignore-daemonsets \
  --delete-emptydir-data

# 5. UsuÅ„ stary pool
az aks nodepool delete \
  --resource-group my-rg \
  --cluster-name my-cluster \
  --name bluepool
```

---

## ğŸ‘· Upgrade Worker Nodes

### **On-Premises**

```bash
# Dla kaÅ¼dego worker node (po kolei!):

# 1. Cordon
kubectl cordon worker-1

# 2. Drain
kubectl drain worker-1 \
  --ignore-daemonsets \
  --delete-emptydir-data \
  --grace-period=60

# 3. SSH do node i upgrade
ssh worker-1
apt-get update
apt-mark unhold kubeadm kubelet kubectl
apt-get install -y \
  kubeadm=1.29.0-00 \
  kubelet=1.29.0-00 \
  kubectl=1.29.0-00
apt-mark hold kubeadm kubelet kubectl

# 4. Upgrade node config
kubeadm upgrade node

# 5. Restart kubelet
systemctl daemon-reload
systemctl restart kubelet

# 6. Uncordon
kubectl uncordon worker-1

# 7. Weryfikacja
kubectl get nodes
```

---

### **Azure AKS: Max-Surge**

```bash
# Konfiguruj max-surge dla bezpiecznego upgrade
az aks nodepool update \
  --resource-group my-rg \
  --cluster-name my-cluster \
  --name nodepool1 \
  --max-surge 33%

# Upgrade z automatycznym rolling update
az aks nodepool upgrade \
  --resource-group my-rg \
  --cluster-name my-cluster \
  --name nodepool1 \
  --kubernetes-version 1.29.0
```

**Jak dziaÅ‚a max-surge:**

```
Masz 3 nodes + max-surge 33% = +1 tymczasowy node

FAZA 1: Dodaj surge node
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Node 1 (old)  Node 2 (old)  Node 3    â”‚
â”‚                                        â”‚
â”‚            + Node 4-temp (new) âœ¨      â”‚
â”‚                                        â”‚
â”‚ Capacity: 133%                         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

FAZA 2-4: Rolling upgrade kaÅ¼dego node
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Node 1 ğŸ’¨ drain                        â”‚
â”‚ Node 1 âœ¨ upgrade                      â”‚
â”‚ Node 2 ğŸ’¨ drain                        â”‚
â”‚ Node 2 âœ¨ upgrade                      â”‚
â”‚ Node 3 ğŸ’¨ drain                        â”‚
â”‚ Node 3 âœ¨ upgrade                      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

FAZA 5: UsuÅ„ surge node
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Node 1 (new)  Node 2 (new)  Node 3    â”‚
â”‚ Node 4-temp âŒ deleted                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ›¡ï¸ Mechanizmy ochrony przed downtime

### **1. PodDisruptionBudget (PDB)** â­ MUST HAVE

```yaml
apiVersion: policy/v1
kind: PodDisruptionBudget
metadata:
  name: my-app-pdb
spec:
  minAvailable: 2    # Minimum 2 pody ZAWSZE muszÄ… dziaÅ‚aÄ‡
  selector:
    matchLabels:
      app: my-app
```

**PrzykÅ‚ad dziaÅ‚ania:**

```
BEZ PDB:                        Z PDB:
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”           â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ kubectl drain    â”‚           â”‚ kubectl drain    â”‚
â”‚                  â”‚           â”‚                  â”‚
â”‚ Usuwa wszystkie  â”‚           â”‚ Czeka aÅ¼ bÄ™dzie  â”‚
â”‚ pody             â”‚           â”‚ bezpiecznie      â”‚
â”‚                  â”‚           â”‚                  â”‚
â”‚ 3 â†’ 0 podÃ³w      â”‚           â”‚ 3 â†’ 2 â†’ 3 podÃ³w  â”‚
â”‚ âŒ DOWNTIME!     â”‚           â”‚ âœ… Zero DT!      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜           â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

### **2. Readiness & Liveness Probes**

```yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: my-app
spec:
  replicas: 3
  template:
    spec:
      containers:
      - name: app
        image: my-app:1.0
        
        # Czy aplikacja Å¼yje?
        livenessProbe:
          httpGet:
            path: /healthz
            port: 8080
          initialDelaySeconds: 30
          periodSeconds: 10
        
        # Czy aplikacja gotowa na ruch?
        readinessProbe:
          httpGet:
            path: /ready
            port: 8080
          periodSeconds: 5
          failureThreshold: 3
```

**Jak to dziaÅ‚a podczas drain:**

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 1. kubectl drain node                  â”‚
â”‚    â†“                                   â”‚
â”‚ 2. Pod otrzymuje SIGTERM               â”‚
â”‚    â†“                                   â”‚
â”‚ 3. Readiness probe = false             â”‚
â”‚    â†“                                   â”‚
â”‚ 4. Service przestaje kierowaÄ‡ ruch     â”‚
â”‚    â†“                                   â”‚
â”‚ 5. PreStop hook (jeÅ›li jest)           â”‚
â”‚    â†“                                   â”‚
â”‚ 6. Czeka terminationGracePeriod (30s)  â”‚
â”‚    â†“                                   â”‚
â”‚ 7. Aplikacja zamyka siÄ™ gracefully     â”‚
â”‚    â†“                                   â”‚
â”‚ 8. Pod usuniÄ™ty                        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

âœ… Zero utraconych requestÃ³w!
```

---

### **3. Graceful Shutdown**

```yaml
apiVersion: apps/v1
kind: Deployment
spec:
  template:
    spec:
      terminationGracePeriodSeconds: 60  # Czas na zamkniÄ™cie
      
      containers:
      - name: app
        lifecycle:
          preStop:
            exec:
              # Poczekaj 15s na zakoÅ„czenie requestÃ³w
              command: ["/bin/sh", "-c", "sleep 15"]
```

**Timeline shutdown:**

```
0s         15s              60s
â”‚          â”‚                â”‚
â–¼          â–¼                â–¼
SIGTERM â†’ PreStop â†’ Graceful â†’ SIGKILL
          hook     shutdown   (force)

           â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
           terminationGrace
           PeriodSeconds
```

---

### **4. Replicas >= 2**

```yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: my-app
spec:
  replicas: 3  # Minimum 2, lepiej 3+
  
  selector:
    matchLabels:
      app: my-app
```

**Dlaczego >= 2?**

```
1 replica:                  3+ replicas:
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”               â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Pod 1    â”‚               â”‚ Pod 1    â”‚ â† drain
â”‚ â–¼        â”‚               â”‚ Pod 2    â”‚ â† obsÅ‚uguje ruch
â”‚ Drain    â”‚               â”‚ Pod 3    â”‚ â† obsÅ‚uguje ruch
â”‚ âŒ DOWN! â”‚               â”‚ âœ… OK!   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜               â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

### **5. Anti-Affinity Rules**

```yaml
apiVersion: apps/v1
kind: Deployment
spec:
  template:
    spec:
      affinity:
        podAntiAffinity:
          requiredDuringSchedulingIgnoredDuringExecution:
          - labelSelector:
              matchLabels:
                app: my-app
            topologyKey: kubernetes.io/hostname
```

**Co to daje:**

```
BEZ Anti-Affinity:              Z Anti-Affinity:
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Node 1:             â”‚         â”‚ Node 1:             â”‚
â”‚  - Pod 1            â”‚         â”‚  - Pod 1            â”‚
â”‚  - Pod 2            â”‚         â”‚                     â”‚
â”‚  - Pod 3            â”‚         â”‚ Node 2:             â”‚
â”‚                     â”‚         â”‚  - Pod 2            â”‚
â”‚ âŒ Single point     â”‚         â”‚                     â”‚
â”‚    of failure!      â”‚         â”‚ Node 3:             â”‚
â”‚                     â”‚         â”‚  - Pod 3            â”‚
â”‚                     â”‚         â”‚                     â”‚
â”‚                     â”‚         â”‚ âœ… Rozproszone      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ“Š PorÃ³wnanie: On-Premises vs Azure AKS

### **Szybkie porÃ³wnanie**

| Aspekt | ğŸ¢ On-Premises | â˜ï¸ Azure AKS |
|--------|---------------|-------------|
| **Control Plane downtime** | âš ï¸ 30-60s (single)<br>âœ… 0s (HA) | âœ… Zawsze 0s |
| **Czas upgrade** | ğŸ”´ 1-3h | ğŸŸ¢ 15-30min |
| **ZÅ‚oÅ¼onoÅ›Ä‡** | ğŸ”´ Wysoka | ğŸŸ¢ Niska |
| **Wymagana wiedza** | ğŸ”´ GÅ‚Ä™boka | ğŸŸ¢ Podstawowa |
| **Automatyzacja** | ğŸŸ¡ Musisz zbudowaÄ‡ | âœ… Wbudowana |
| **Rollback** | ğŸ”´ Trudny (etcd restore) | ğŸŸ¢ Åatwiejszy |
| **Backup etcd** | âš ï¸ Musisz sam | âœ… Automatyczny |
| **Kontrola** | ğŸŸ¢ PeÅ‚na | ğŸŸ¡ Ograniczona |
| **Koszt operacyjny** | ğŸŸ¡ Czas zespoÅ‚u | ğŸŸ¢ Niski |
| **Koszt finansowy** | ğŸŸ¢ StaÅ‚y (hardware) | ğŸ”´ Surge = wyÅ¼szy |
| **Monitoring** | âš ï¸ Musisz skonfigurowaÄ‡ | âœ… Wbudowany (Azure Monitor) |
| **SLA** | âš ï¸ Twoja odpowiedzialnoÅ›Ä‡ | âœ… 99.95% (uptime SLA) |

---

### **Kiedy wybraÄ‡ On-Premises?**

âœ… **Wybierz On-Prem gdy:**
- Masz wymagania compliance (dane w kraju)
- Masz juÅ¼ infrastrukturÄ™ i zespÃ³Å‚
- Potrzebujesz peÅ‚nej kontroli
- Koszty chmury sÄ… zbyt wysokie
- Specyficzne wymagania hardware

âŒ **Nie wybieraj On-Prem gdy:**
- Brak doÅ›wiadczonego zespoÅ‚u
- Potrzebujesz szybkiego startu
- Chcesz skupiÄ‡ siÄ™ na aplikacjach, nie infrastrukturze

---

### **Kiedy wybraÄ‡ Azure AKS?**

âœ… **Wybierz AKS gdy:**
- Chcesz szybki start
- Brak zespoÅ‚u infrastrukturalnego
- Potrzebujesz elastycznoÅ›ci (scale up/down)
- WaÅ¼na jest automatyzacja
- Chcesz integracji z Azure services

âŒ **Nie wybieraj AKS gdy:**
- Wymagania compliance uniemoÅ¼liwiajÄ… cloud
- Masz juÅ¼ duÅ¼Ä… inwestycjÄ™ w on-prem
- Potrzebujesz specyficznych customizacji control plane

---

## ğŸ’¡ Best Practices

### **ğŸ” BezpieczeÅ„stwo**

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ âœ… BACKUP etcd przed kaÅ¼dym upgrade         â”‚
â”‚ âœ… Test restore na non-prod                 â”‚
â”‚ âœ… Zaszyfruj backupy                        â”‚
â”‚ âœ… Przechowuj backupy w innej lokalizacji   â”‚
â”‚ âœ… Automatyczne backupy (cron/Azure)        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

### **ğŸ§ª Testowanie**

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ âœ… ZAWSZE testuj na dev/staging             â”‚
â”‚ âœ… Testuj peÅ‚ny flow (upgrade + rollback)   â”‚
â”‚ âœ… Load testing po upgrade                  â”‚
â”‚ âœ… Chaos engineering (opcjonalnie)          â”‚
â”‚ âœ… Dokumentuj kaÅ¼dy test                    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

### **ğŸ“‹ Planowanie**

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ âœ… Zaplanuj okno maintenance                â”‚
â”‚ âœ… Komunikuj z zespoÅ‚em i stakeholders      â”‚
â”‚ âœ… Przygotuj rollback plan                  â”‚
â”‚ âœ… SprawdÅº K8s release notes                â”‚
â”‚ âœ… SprawdÅº version skew policy              â”‚
â”‚ âœ… Przygotuj runbook (krok po kroku)        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

### **ğŸ”„ Podczas upgrade**

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ âœ… Upgrade po kolei (node po node)          â”‚
â”‚ âœ… Czekaj 5-10 min miÄ™dzy nodes             â”‚
â”‚ âœ… Monitoruj metryki (CPU, RAM, errors)     â”‚
â”‚ âœ… Sprawdzaj logi aplikacji                 â”‚
â”‚ âœ… Watch kubectl get pods -A                â”‚
â”‚ âœ… Miej zespÃ³Å‚ on-call gotowy               â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

### **âœ… Po upgrade**

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ âœ… Weryfikuj wszystkie komponenty           â”‚
â”‚ âœ… Test aplikacji end-to-end                â”‚
â”‚ âœ… SprawdÅº metryki przez 24h                â”‚
â”‚ âœ… Nowy backup etcd                         â”‚
â”‚ âœ… Dokumentuj zmiany i incydenty            â”‚
â”‚ âœ… Retrospektywa z zespoÅ‚em                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

### **ğŸ“Š Monitoring**

**Kluczowe metryki do obserwacji:**

```yaml
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ CONTROL PLANE:                          â”‚
â”‚  - API Server response time             â”‚
â”‚  - API Server error rate                â”‚
â”‚  - etcd latency                         â”‚
â”‚  - etcd DB size                         â”‚
â”‚  - Controller Manager lag               â”‚
â”‚  - Scheduler latency                    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ NODES:                                  â”‚
â”‚  - CPU utilization                      â”‚
â”‚  - Memory utilization                   â”‚
â”‚  - Disk I/O                             â”‚
â”‚  - Network bandwidth                    â”‚
â”‚  - Pod count per node                   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ APLIKACJE:                              â”‚
â”‚  - Pod restart count                    â”‚
â”‚  - Pod eviction rate                    â”‚
â”‚  - Application error rate               â”‚
â”‚  - Application response time            â”‚
â”‚  - Request rate                         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---


### **ğŸ“š Dokumentacja**

- [Kubernetes Official Documentation](https://kubernetes.io/docs/)
- [kubeadm Upgrade Guide](https://kubernetes.io/docs/tasks/administer-cluster/kubeadm/kubeadm-upgrade/)
- [Azure AKS Documentation](https://docs.microsoft.com/en-us/azure/aks/)
- [etcd Disaster Recovery](https://kubernetes.io/docs/tasks/administer-cluster/configure-upgrade-etcd/)
- [Kubernetes Version Skew Policy](https://kubernetes.io/releases/version-skew-policy/)


---

## ğŸ¬ Podsumowanie koÅ„cowe

### **ZÅ‚ote zasady Kubernetes Maintenance:**

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  1ï¸âƒ£  "Cattle, not Pets"                         â”‚
â”‚     Node'y wymieniaj, nie naprawiaj             â”‚
â”‚                                                  â”‚
â”‚  2ï¸âƒ£  Backup etcd ZAWSZE przed zmianami          â”‚
â”‚     To Twoja siatka bezpieczeÅ„stwa              â”‚
â”‚                                                  â”‚
â”‚  3ï¸âƒ£  Test na non-prod NAJPIERW                  â”‚
â”‚     Nigdy nie eksperymentuj na produkcji        â”‚
â”‚                                                  â”‚
â”‚  4ï¸âƒ£  PodDisruptionBudget dla WSZYSTKICH aplikacjiâ”‚
â”‚     To gwarancja zero downtime                  â”‚
â”‚                                                  â”‚
â”‚  5ï¸âƒ£  Upgrade po kolei, czekaj i monitoruj       â”‚
â”‚     Lepiej wolniej, ale bezpiecznie             â”‚
â”‚                                                  â”‚
â”‚  6ï¸âƒ£  Automatyzuj wszystko co siÄ™ da             â”‚
â”‚     Infrastructure as Code                      â”‚
â”‚                                                  â”‚
â”‚  7ï¸âƒ£  Dokumentuj kaÅ¼dÄ… zmianÄ™                    â”‚
â”‚     PrzyszÅ‚y Ty podziÄ™kuje                      â”‚
â”‚                                                  â”‚
â”‚  8ï¸âƒ£  Zawsze miej rollback plan                  â”‚
â”‚     Nadzieja nie jest strategiÄ…                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

